{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, losses\n",
    "import os\n",
    "from tensorflow.keras import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/phoelapyae/Downloads/stack_overflow_16k'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 8000 files belonging to 4 classes.\n",
      "Using 6400 files for training.\n",
      "Found 8000 files belonging to 4 classes.\n",
      "Using 1600 files for validation.\n"
     ]
    }
   ],
   "source": [
    "raw_train_ds = preprocessing.text_dataset_from_directory(train_dir, seed=42, validation_split=0.2, subset='training', batch_size=batch_size)\n",
    "raw_val_ds = preprocessing.text_dataset_from_directory(train_dir, seed=42, validation_split=0.2, subset='validation', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 8000 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "raw_test_ds = preprocessing.text_dataset_from_directory(test_dir, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "\n",
    "def custom_standardize(text):\n",
    "    text = tf.strings.lower(text)\n",
    "    stripped_text = tf.strings.regex_replace(text, '<br >', ' ')\n",
    "    return tf.strings.regex_replace(stripped_text, '[%s]' % re.escape(string.punctuation), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "max_features = 10000\n",
    "maxlen = 300\n",
    "\n",
    "vectorize_layer = TextVectorization(max_tokens=max_features, output_sequence_length=maxlen, output_mode='int', standardize=custom_standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "len(vectorize_layer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = raw_train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "len(vectorize_layer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "raw_train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "raw_val_ds = raw_val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    vectorize_layer,\n",
    "    layers.Embedding(max_features + 1, 16),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(4, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=optimizers.Adam(), loss=losses.SparseCategoricalCrossentropy(), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "200/200 [==============================] - 4s 16ms/step - loss: 1.3836 - acc: 0.2870 - val_loss: 1.3604 - val_acc: 0.3369\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 1.3332 - acc: 0.4348 - val_loss: 1.2052 - val_acc: 0.5944\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 1.1548 - acc: 0.5974 - val_loss: 1.0069 - val_acc: 0.6656\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.9627 - acc: 0.6864 - val_loss: 0.8571 - val_acc: 0.7269\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.8105 - acc: 0.7376 - val_loss: 0.7479 - val_acc: 0.7475\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.6958 - acc: 0.7695 - val_loss: 0.6746 - val_acc: 0.7581\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.6140 - acc: 0.7913 - val_loss: 0.6257 - val_acc: 0.7706\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.5517 - acc: 0.8142 - val_loss: 0.5928 - val_acc: 0.7812\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.4999 - acc: 0.8308 - val_loss: 0.5701 - val_acc: 0.7837\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.4567 - acc: 0.8496 - val_loss: 0.5533 - val_acc: 0.7887\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.4198 - acc: 0.8673 - val_loss: 0.5432 - val_acc: 0.7900\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.3893 - acc: 0.8770 - val_loss: 0.5363 - val_acc: 0.7912\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.3600 - acc: 0.8872 - val_loss: 0.5323 - val_acc: 0.7937\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.3312 - acc: 0.8991 - val_loss: 0.5313 - val_acc: 0.7925\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.3051 - acc: 0.9105 - val_loss: 0.5319 - val_acc: 0.7912\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.2849 - acc: 0.9152 - val_loss: 0.5348 - val_acc: 0.7931\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2652 - acc: 0.9250 - val_loss: 0.5388 - val_acc: 0.7900\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2436 - acc: 0.9310 - val_loss: 0.5450 - val_acc: 0.7894\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2293 - acc: 0.9360 - val_loss: 0.5524 - val_acc: 0.7862\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2131 - acc: 0.9427 - val_loss: 0.5596 - val_acc: 0.7869\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(raw_train_ds, epochs=20, validation_data=raw_val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "250/250 [==============================] - 8s 31ms/step - loss: 0.6240 - acc: 0.7771\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.6239853501319885, 0.7771250009536743]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "model.evaluate(raw_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(b'\"hacking select multiple in blank, flicke i\\'ve hacked html\\'s &lt; select multiple > with blank, according to my customer\\'s specifications:...clicking an item only toggles that item\\'s selected status..other selected items stay selected....the little bit of blank remembers all selected values..when the user clicks, only the option he clicks will be selected..the blank selects the options he remembers...however, it causes a flicker effect. i doubt there is any solution for this, but i felt i had to ask just in case, does anyone know of a way to delay the rendering, or any other solution to accomplish this, without a flicker?..best regards...edit: here is the code..var choices=new array();.function prepmulti(){.    var m=document.queryselectorall(\\'select\\');.    for(var i=0;i&lt;m.length;i++).        if(m[i].id!=\\'\\'){.            m[i].onclick=toggle;.            choices.push(new array());.        }.}.function toggle(){.    var sel, x;.    for(var i=0; i&lt;this.options.length;i++).        if(this.options[i].selected){.            sel=i;.            break;.        }.    if((x=choices[this.id].indexof(sel))&lt;0).        choices[this.id].push(sel);.    else{.        choices[this.id].splice(x, 1);.        this.options[sel].selected=false;.        }.    for(i=0;i&lt;choices[this.id].length;i++).            this.options[choices[this.id][i]].selected=true;.}..&lt;body onload=\\'prepmulti();\\'&gt;...the select multiples have ids 0, 1, 2, etc... if you give them other ids, the code must be modified a little.\"\\n', shape=(), dtype=string)\ntf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "texts, labels = next(iter(raw_test_ds))\n",
    "first_question, first_label = texts[1], labels[1]\n",
    "print(first_question)\n",
    "print(first_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predict = model.predict(tf.expand_dims(first_question, -1))\n",
    "print(np.argmax(predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}