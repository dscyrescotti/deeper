{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nprint(tf.__version__)\n\nurl = 'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz'\ndata_dir = tf.keras.utils.get_file(origin=url, fname='flower_photos', untar=True)","execution_count":2,"outputs":[{"output_type":"stream","text":"2.3.1\nDownloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n228818944/228813984 [==============================] - 2s 0us/step\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"print(data_dir)","execution_count":3,"outputs":[{"output_type":"stream","text":"/root/.keras/datasets/flower_photos\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 1234\nbatch_size = 32\nimg_width = 180\nimg_height = 180","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_dataset(subset):\n    dataset = tf.keras.preprocessing.image_dataset_from_directory(data_dir, validation_split=0.2, seed=seed, image_size=(img_width, img_height), batch_size=batch_size, subset=subset)\n    return dataset","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds = make_dataset('training')","execution_count":6,"outputs":[{"output_type":"stream","text":"Found 3670 files belonging to 5 classes.\nUsing 2936 files for training.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_ds = make_dataset('validation')","execution_count":7,"outputs":[{"output_type":"stream","text":"Found 3670 files belonging to 5 classes.\nUsing 734 files for validation.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds.class_names","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds = train_ds.cache().prefetch(buffer_size=2)\nval_ds = val_ds.cache().prefetch(buffer_size=2)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import layers\n\nmodel = tf.keras.Sequential([\n    layers.experimental.preprocessing.Rescaling(1./255),\n    layers.Conv2D(32, 3, activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(32, 3, activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(32, 3, activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(5, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss=tf.losses.SparseCategoricalCrossentropy(), metrics=['acc'])","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_ds, validation_data=val_ds, epochs=10)","execution_count":null,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n92/92 [==============================] - 69s 751ms/step - loss: 1.3060 - acc: 0.4189 - val_loss: 1.1574 - val_acc: 0.5014\nEpoch 2/10\n92/92 [==============================] - 64s 698ms/step - loss: 1.0937 - acc: 0.5324 - val_loss: 1.0305 - val_acc: 0.5817\nEpoch 3/10\n33/92 [=========>....................] - ETA: 38s - loss: 1.0508 - acc: 0.5578","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"See this tutorial (https://www.tensorflow.org/tutorials/load_data/images#using_tfdata_for_finer_control) if you want to load image data using **`tf.data`**"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}